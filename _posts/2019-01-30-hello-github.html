---
layout: default
title: 你好，GitHub！
---
<h2>{{ page.title }}</h2>
<p>我的第一篇文章</p>
  <a href="https://blog.csdn.net/pipisorry/article/details/51707366">利用github page和github自带的jekyll搭建简单的博客教程《一》</a></br>
  <a href="https://www.jianshu.com/p/558a5d50e077">利用github page和github自带的jekyll搭建简单的博客教程《二》</a>
  
  <h2>机器学习技术栈</h2>
  <p>
    去知乎上可以搜到很多推荐的学习路线，问题就是太多了，我就先列出一些必需的知识和项目方向，学习还是要一步一步积累的。
需要的基础技能：
Various level of math, including probability, statistics, algebra, calculus, logic and algorithms.
Bayesian networking or graphical modeling, including neural nets.
Physics, engineering and robotics.
Computer science, programming languages and coding.
Cognitive science theory.
关于数学基础：
线性代数，最小二乘，PCA，SVD
微积分基础，梯度下降法，牛顿法，神经网络后向传播
概率论基础，条件概率，贝叶斯定理，logistic
很多小伙伴觉得自己数学不好，是不是就会很难入门，上一篇文章中提到过，入门并不难，本科时的高数就可以用，如果有时间，可以复习一下 线性代数，微积分，概率论，这些是基础。就算学习深度学习时遇到了复杂的模型公式，有了这些基础，应该也是可以看懂的。


库：
TensorFlow + Keras
Python: Numpy, Pandas, Matplotlib, Scipy
机器学习算法基础：
分类
回归
聚类
关联
决策树
支持向量机(SVM)
神经网络
深度学习
增强学习
交叉检验
贝叶斯
模型训练基础：
Back Propagation (BP)
Stochastic Gradient Descent (SGD)
神经网络：
Feedforward Neural Network
Convolutional Neural Network (CNN)
Recurrent Neural Network (RNN)
Deep Feedforward Network (DFN)
自然语言处理：推荐课程 cs224d
word embedding
Softmax
有趣的项目：
人脸识别
手写识别
物体识别
语言识别
个性化推荐
预测价格
用户画像
行为分析
无人车
照片油画化
文章生成
音乐生成
诗歌生成
聊天机器人
游戏机器人


作者：不会停的蜗牛
链接：https://www.jianshu.com/p/0b0a1750e310
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。
来源： <http://3ms.huawei.com/km/blogs/details/5661405>
 
  </p>
</br>

<h2>降维算法</h2>
<p>
  PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。 
降维算法如下：
设有m条n维数据。
1）将原始数据按列组成n行m列矩阵X 
2）将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值 
3）求出协方差矩阵C=\frac{1}{m}XX^\mathsf{T} 
4）求出协方差矩阵的特征值及对应的特征向量 
5）将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P 
6）Y=PX即为降维到k维后的数据

SVD（Singular Value Decomposition）奇异值分解。在线性代数中，SVD是复杂矩阵的因式分解。对于给定的m * n矩阵M，存在分解使得M=UΣV，其中U和V是酉矩阵，Σ是对角矩阵, 实际上，PCA是SVD的一个简单应用。在计算机视觉中，第一个人脸识别算法使用PCA和SVD来将面部表示为“特征面”的线性组合，进行降维，然后通过简单的方法将面部匹配到身份，虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。
 
 
LDA（Linear Discriminant Analysis），简称为LDA。也称为Fisher线性判别（Fisher Linear Discriminant，FLD），是模式识别的经典算法，在1996年由Belhumeur引入模式识别和人工智能领域。
基本思想是将高维的模式样本投影到最佳鉴别矢量空间，以达到抽取分类信息和压缩特征空间维数的效果，投影后保证模式样本在新的子空间有最大的类间距离和最小的类内距离，即模式在该空间中有最佳的可分离性。
LDA与前面介绍过的PCA都是常用的降维技术。PCA主要是从特征的协方差角度，去找到比较好的投影方式。LDA更多的是考虑了标注，即希望投影后不同类别之间数据点的距离更大，同一类别的数据点更紧凑。
 
Autoencoder自动编码器是是多层神经网络，其中输入层和输出层表示相同的含义，具有相同的节点数, 即输出层的神经元数量完全等于输入层神经元的数量。隐藏层的神经元数量少于输出层的神经元数量。它是神经网络NN的一种，经过训练后能尝试将输入复制
到输出，换句话说，就是使输出的内容和输入的内容一样。Autoencoder自动编码器学习的是一个输入输出相同的“恒等函数”。自动编码器的网络结构很简单，包括Input
Layer,Hidden Layer和Output Layer。其中，动编码器内部有一个隐含层h，可以产生编码来表示输入。该网络可以看作由两部分组成：一个编码器h=f(x)和一个生成重构的解码器r=g(h)。最后使得x约等于g(f(x))。可以通过设计网络使得x=g(f(x))。

来源： <http://3ms.huawei.com/km/blogs/details/5630071>
 </p>
  
  <h2>搜索和排名(个人总结)</h2>
  <p>
    代码：python
书籍：集体智慧编程
模块库：urllib、sqlite3、bs4
数据库：sqlite3（可更换其他的数据库）

摘要：虽然是个简单的搜索引擎，但是和其他大型的搜索引擎结构大致差不多（在文本分析、内容解析、词干提取、分布式、数据库优化等等实现上存在很大的差距），并且还介绍包含了很多网页的排名方法以及利用了神经网络来改善网页排名。

结构组成：

爬虫类
1、爬取网页
    利用urllib打开url链接获取网页的response对象
2、网页内容解析
    通过response对象读取网页内容，利用BeautifulSoup解析网页内容，获取不带标签的网页内容，以及网页包含的url链接和单词
3、网页内容存储（数据库中）
    将该网页的url、包含的单词、url和单词的对应关系存入数据库中（由于查询较频繁，可建立索引）（可分成三个表）
4、网页链接指向关系存储
    将由一个网页链向另一个网页的关系存入数据库中（单独一个表），同时也存储一个网页是通过哪些单词跳转到另一个网页的（查询问题比较明显时，可建立索引）（单独一个表）。

搜索类
1、解析搜索关键字
    对输入的搜索，将其解析成多个单词。
2、利用搜索关键字从数据库中查询相关的url
    遍历搜索的单词，查询和该单词有关联的链接
3、对网页进行相关度评分
    通过评估函数，以基于网页内容信息和基于网页外部信息的方式对网页相对于查询关键字的相关度进行估分
    
    基于网页内容信息：
            单词出现的频繁度（次数）、单词出现的位置（一般来讲，单词出现在标题或者越靠前，网页相关度越高）、
            查询单词之间的距离（查询单词之间，关联性越强，距离越近，相关度越高）、
    基于网页外部信息:
                外部链接回指（权威性）、pagerank值、基于用户的点击行为评估
4、向用户返回排序后的url集合
    可利用多种评估方式对网页进行评分，对不同的评估方式可以设置不同的权重，对评分进行归一化（可将归一化单独写一个函数，每个评估函数最后都可调用一次归一化函数），使每种评估方式都有相同的取值区间    （同等重要），最后再加权求得综合评分。
5、根据用户对url的点击行为，以及用户查询的关键字，建立神经网络，改善查询词对url的相关性。
    书中，将神经网络的每个节点信息和每层权重存储在数据库中的，可以借鉴一下（之前我是直接用变量存储的），而且需要新的隐藏层节点时再建立节点信息。
  </p>
    
<p>{{ page.date | date_to_string }}</p>
